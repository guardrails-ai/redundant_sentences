## Overview

| Developed by | Guardrails AI |
| --- | --- |
| Date of development | Feb 15, 2024 |
| Validator type | Chatbots, QA |
| Blog |  |
| License | Apache 2 |
| Input/Output | Output |

## Description

This validator removes redundant sentences from an LLM response, resulting in a response that is more concise.

### Resources required

- Dependencies: `the_fuzz`

## Installation

```bash
$ gudardrails hub install hub://guardrails/redundant_sentences
```

## Usage Examples

### Validating string output via Python

In this example, we apply the validator to a string output generated by an LLM.

```python
redundant_sentences_validator = RemoveRedundantSentences(
	threshold=80,
	on_fail="noop"
)

# Create Guard with Validator
guard = Guard.from_string(
    validators=[redundant_sentences_validator, ...],
    num_reasks=2,
)

guard(
    "LLM text with possible redundant sentences",
    metadata={"translation_source": "Original text"}
)
```

## Validating JSON output via Python

In this example, we apply the validator to a string field of a JSON output generated by an LLM.

```python
# Import Guard and Validator
from pydantic import BaseModel
from guardrails.hub import ValidChoices
from guardrails import Guard

val = ValidChoices(
		choices=['cat', 'dog', 'bird'],
		on_fail="fix"
)

# Create Pydantic BaseModel
class PetInfo(BaseModel):
		pet_name: str
		pet_type: str = Field(
				description="Type of pet", validators=[val]
		)

# Create a Guard to check for valid Pydantic output
guard = Guard.from_pydantic(output_class=PetInfo)

# Run LLM output generating JSON through guard
guard.parse("""
{
		"pet_name": "Caesar",
		"pet_type": "dog"
}
""")
```

## API Ref

- `threshold`: The threshold used for matching redundancy.
